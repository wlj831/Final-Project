{
  "hash": "c850b79043460b8c4be352385034152f",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"M07-2-Application Assignment for R Data Types\"\nauthor: \"William Jackson\"\ndate: \"2025-05-15 15:36:51\"\nformat: \n  html:\n    theme: darkly\n    toc: true\n    toc-location: right\n    toc-depth: 4\n    code-fold: false\n    code-line-numbers: true\n    code-link: true\n    number-sections: true\n    embed-resources: true\n    df-print: paged\nexecute: \n  freeze: auto\n  echo: fenced\n  warning: false\n  error: false\n---\n\n\n\n\n\n# Q1. Vectors\n\n> (1) Create a numeric vector called \"stock_prices\" with the following data points: 42.5, 43.0, 44.1, and 2.7. Next, verify the class of it. (2) Create a character vector called \"stock_company\" consisting of the following company names: Microsoft, Apple, Facebook, and Tesla. (3) Create a character vector called \"stock_ticker\" consisting of stock tickers corresponding to the companies in the \"stock_company\" vector: MSFT, AAPL, FB, and TSLA. Then verify its data type. (4) Create a logical vector called \"make_cars\" consisting of the four logical values: FALSE, FALSE, FALSE, and TRUE. (5) After that, add 5 to the vector \"stock_prices\" and assign the result to the same \"stock_prices\" vector, essentially updating the existing stock prices vector. (6) Name each element in \"stock_prices\" vector, using the \"stock_company\" vector that you created above, and print the stock_prirces vector to confirm that each element has a company name associated with it.\n\n\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n# Creating Character Vectors for \"Stock Prices\" \nstock_price <- c(42.5, 43.0, 44.1, 2.7)\n\n#Verify the class of \"stock_price\" \nclass(stock_price) #should return numeric \n\n# 2 Create a character vector \"stock_company\" \nstock_company <- c(\"Microsoft\", \"Apple\", \"Facebook\", \"Tesla\")\n\n# 3 Create a character vector #stock_ticker\"\nstock_ticker <- c(\"MSFT\", \"AAPL\", \"FB\", \"TSLA\")\n\n# 4 Create a Logical vector \"make_cars\"\nmake_cars <- c(FALSE, FALSE, FALSE, TRUE)\n\n# 5 Add 5 to each element in the \"stock_prices\" and update its reference\nstock_price <- stock_price + 5 \n\n# 6 Name Elements in \"stock_prices\" using \"stock_companies\" vector \nnames(stock_price) <- stock_company\n\n# Print the updated table for confirmation of vector was properly assigned\nprint(stock_price)\n```\n````\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"numeric\"\nMicrosoft     Apple  Facebook     Tesla \n     47.5      48.0      49.1       7.7 \n```\n\n\n:::\n:::\n\n\n\n\n# Q2. Creating and cleaning a data frame in base R (0.5 pts)\n\n> Q2.1: Create a data frame called \"stock_info.df\" which is composed of the four vectors created in exercises #2 and #3 above. Verify the number of rows and columns, and also display the summary.\n\n\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n# Creating the data frame \"stock_info.df\" \nstock_info.df <- data.frame(\n  stock_company = stock_company,\n  stock_ticker = stock_ticker, \n  stock_price = stock_price,\n  make_cars = make_cars\n)\n\n#Verify the number of rows and columns \ndim(stock_info.df)\n\n#Display the summary of the data frame \nsummary(stock_info.df)\n\n#Print the data frame to check its contents \nprint(stock_info.df)\n```\n````\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 4 4\n stock_company      stock_ticker        stock_price    make_cars      \n Length:4           Length:4           Min.   : 7.70   Mode :logical  \n Class :character   Class :character   1st Qu.:37.55   FALSE:3        \n Mode  :character   Mode  :character   Median :47.75   TRUE :1        \n                                       Mean   :38.08                  \n                                       3rd Qu.:48.27                  \n                                       Max.   :49.10                  \n          stock_company stock_ticker stock_price make_cars\nMicrosoft     Microsoft         MSFT        47.5     FALSE\nApple             Apple         AAPL        48.0     FALSE\nFacebook       Facebook           FB        49.1     FALSE\nTesla             Tesla         TSLA         7.7      TRUE\n```\n\n\n:::\n:::\n\n\n\n\n> Q2.2: (1) Let's suppose that there was a data entry error in \"stock_prices\" vector such that Tesla's original stock price was 42.7, not 2.7. Also, note that previously you updated the stock price by adding 5 to all elements in the stock_prices vector, making the updated stock price of Tesla 7.7. (2) Now that we know there was a data entry error, we need to update Tesla's stock price correctly in the data frame created in #5. In short, we need to replace 7.7 with 47.7, which would have been the correct stock price for Tesla in Exercise #3.4, had there not been an error in the first place. (3) Do the necessary coding to execute the correction to the stock_info.df data frame. Confirm the operation was successful by printing the data frame.\n\n\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n# (1) Identify the incorrect Tesla stock price and correct it\n# Tesla's corrected stock price should be 42.7 + 5 = 47.7\n\n# Correct Tesla's stock price in the existing \"stock_price\" column\nstock_info.df$stock_price[stock_info.df$stock_company == \"Tesla\"] <- 47.7\n\n# Print the updated data frame to confirm the change\nprint(stock_info.df)\n```\n````\n\n::: {.cell-output .cell-output-stdout}\n\n```\n          stock_company stock_ticker stock_price make_cars\nMicrosoft     Microsoft         MSFT        47.5     FALSE\nApple             Apple         AAPL        48.0     FALSE\nFacebook       Facebook           FB        49.1     FALSE\nTesla             Tesla         TSLA        47.7      TRUE\n```\n\n\n:::\n:::\n\n\n\n\n# Q3. Adding a row or column to a data frame in base R\n\n> Q3.1: (1) Add a new row to the bottom of the existing \"stock_info.df\" data frame with the following information: stock_prices = 50.4, stock_company = General Motors, stock_ticker = GM, and make_cars = TRUE. (2) Print out the updated data frame. (3) Do you see the row name of the last row is \"1\"? You may want to replace this with the correct name, \"General Motors.\" Print the data frame again to confirm you fixed the problem.\n\nHint: You may create a data frame with its four elements set as described above and then use rbind() to append it to the existing data frame, \"stock_info.df\". Also, see how to change row names in RLinks to an external site. to change row names.\n\n\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n# (1) Create a new data frame with the new row data\nnew_row <- data.frame(\n  stock_company = \"General Motors\",\n  stock_ticker = \"GM\",\n  stock_price = 50.4,\n  make_cars = TRUE\n)\n\n# Append the new row to the existing data frame using rbind()\nstock_info.df <- rbind(stock_info.df, new_row)\n\n# (2) Print the updated data frame to confirm the addition\nprint(stock_info.df)\n\n# (3) Rename the last row to \"General Motors\"\nrownames(stock_info.df)[nrow(stock_info.df)] <- \"General Motors\"\n\n# Print the data frame again to confirm the change\nprint(stock_info.df)\n```\n````\n\n::: {.cell-output .cell-output-stdout}\n\n```\n           stock_company stock_ticker stock_price make_cars\nMicrosoft      Microsoft         MSFT        47.5     FALSE\nApple              Apple         AAPL        48.0     FALSE\nFacebook        Facebook           FB        49.1     FALSE\nTesla              Tesla         TSLA        47.7      TRUE\n1         General Motors           GM        50.4      TRUE\n                stock_company stock_ticker stock_price make_cars\nMicrosoft           Microsoft         MSFT        47.5     FALSE\nApple                   Apple         AAPL        48.0     FALSE\nFacebook             Facebook           FB        49.1     FALSE\nTesla                   Tesla         TSLA        47.7      TRUE\nGeneral Motors General Motors           GM        50.4      TRUE\n```\n\n\n:::\n:::\n\n\n\n\n::: {.callout-tip collapse=\"true\"}\n## Explanation of the Code\n\nCreate a new row as a data frame (new_row) containing the required values. Use rbind() to append this new row to stock_info.df. Print the data frame to verify the row was added. Rename the last row using rownames() so that it correctly displays \"General Motors\". Print the final data frame to confirm everything looks correct.\n:::\n\n> Q3.2 (1) Add a new column with the following column name and values: open_price = 47.3, 47.8, 49.5, 47.9 and 55.3. (2) Print out the updated data frame, \"stock_info.df\" to confirm your work.\n\n\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n# (1) Add a new column \"open_price\" with the given values\nstock_info.df$open_price <- c(47.3, 47.8, 49.5, 47.9, 55.3)\n\n# (2) Print the updated data frame to confirm the changes\nprint(stock_info.df)\n```\n````\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                stock_company stock_ticker stock_price make_cars open_price\nMicrosoft           Microsoft         MSFT        47.5     FALSE       47.3\nApple                   Apple         AAPL        48.0     FALSE       47.8\nFacebook             Facebook           FB        49.1     FALSE       49.5\nTesla                   Tesla         TSLA        47.7      TRUE       47.9\nGeneral Motors General Motors           GM        50.4      TRUE       55.3\n```\n\n\n:::\n:::\n\n\n\n\n::: {.callout-tip collapse=\"true\"}\n## Explanation of the Code\n\nAdd a new column open_price to stock_info.df with the specified values. print(stock_info.df) displays the updated data frame to verify the addition.\n:::\n\n# Q4. Creating a new column from existing columns and subsetting\n\n> Q4.1: Now, create a new vector called \"change_stock_prices_percent\" and add it to the existing data frame to show if the stock increased or decreased its price at the end of the day compared to the beginning of the day.\n\nHints: Consider the stock_prices as the closing prices of the stocks for the day. The change_stock_prices_percent can then be calculated as: \\[(closing price - open price) / open price \\* 100\\]. If the outcome is negative value, the stock price has decreased. If the outcome is positive value, stock price has increased. If you are not familiar with the meaning of the operators in the formula above, note the following:\n\n-   : subtraction \n- / : division\n-   : multiplication.\n\n\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n# (1) Calculate the percentage change in stock prices using the formula\nchange_stock_prices_percent <- ((stock_info.df$stock_price - stock_info.df$open_price) / stock_info.df$open_price) * 100\n\n# (2) Add the new column to the existing data frame\nstock_info.df$change_stock_prices_percent <- change_stock_prices_percent\n\n# (3) Print the updated data frame to confirm the addition\nprint(stock_info.df)\n```\n````\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                stock_company stock_ticker stock_price make_cars open_price\nMicrosoft           Microsoft         MSFT        47.5     FALSE       47.3\nApple                   Apple         AAPL        48.0     FALSE       47.8\nFacebook             Facebook           FB        49.1     FALSE       49.5\nTesla                   Tesla         TSLA        47.7      TRUE       47.9\nGeneral Motors General Motors           GM        50.4      TRUE       55.3\n               change_stock_prices_percent\nMicrosoft                        0.4228330\nApple                            0.4184100\nFacebook                        -0.8080808\nTesla                           -0.4175365\nGeneral Motors                  -8.8607595\n```\n\n\n:::\n:::\n\n\n\n\n:::{.callout-tip collapse=\"true\"}\n## Explanation of the Code\n\nFormula:\n\nstock_info.df$stock_price represents the closing price of the stock.\nstock_info.df$open_price represents the opening price.\nThe formula ((closing price - open price) / open price) * 100 calculates the percentage change in stock price.\nThe result of this calculation is stored in a new vector change_stock_prices_percent.\n\nThis vector is then added as a new column in the existing stock_info.df data frame.\n\nThe final step is printing the data frame to confirm that the new column has been added successfully.\n:::\n\n\n>4.2: Which stock has increased its value and which ones have decreased? Use the function \"subset\" to select the two types of stocks.\n\n\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n# (1) Subset stocks that have increased in value (positive change)\nstocks_increased <- subset(stock_info.df, change_stock_prices_percent > 0)\n\n# (2) Subset stocks that have decreased in value (negative change)\nstocks_decreased <- subset(stock_info.df, change_stock_prices_percent < 0)\n\n# (3) Print the results\nprint(\"Stocks that increased in value:\")\nprint(stocks_increased)\n\nprint(\"Stocks that decreased in value:\")\nprint(stocks_decreased)\n```\n````\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"Stocks that increased in value:\"\n          stock_company stock_ticker stock_price make_cars open_price\nMicrosoft     Microsoft         MSFT        47.5     FALSE       47.3\nApple             Apple         AAPL        48.0     FALSE       47.8\n          change_stock_prices_percent\nMicrosoft                    0.422833\nApple                        0.418410\n[1] \"Stocks that decreased in value:\"\n                stock_company stock_ticker stock_price make_cars open_price\nFacebook             Facebook           FB        49.1     FALSE       49.5\nTesla                   Tesla         TSLA        47.7      TRUE       47.9\nGeneral Motors General Motors           GM        50.4      TRUE       55.3\n               change_stock_prices_percent\nFacebook                        -0.8080808\nTesla                           -0.4175365\nGeneral Motors                  -8.8607595\n```\n\n\n:::\n:::\n\n\n\n\n:::{.callout-tip collapse=\"true\"}\n## Explanation of the Code\n\nFormula:\n\nsubset(stock_info.df, change_stock_prices_percent > 0):\n\nThis selects rows where change_stock_prices_percent is greater than 0, indicating the stock price has increased.\nsubset(stock_info.df, change_stock_prices_percent < 0):\n\nThis selects rows where change_stock_prices_percent is less than 0, indicating the stock price has decreased.\nprint() is used to display the results for stocks that have increased or decreased in value.\n:::\n\n# Q5. Matrix (0.5 pts)\n\n>Create a matrix named \"odd.mat\" that consists of odd numbers starting with \"1\" with 10 columns and 5 rows.\n\n>Hints: You can type 50 odd numbers directly, but this is not the best way. preferably, you can use a function called seq() as follows: seq(from = 1, by = 2, length.out = 50).\n\n\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n# Generate the first 50 odd numbers using seq()\nodd_numbers <- seq(from = 1, by = 2, length.out = 50)\n\n# Convert the vector of odd numbers into a matrix with 10 columns and 5 rows\nodd.mat <- matrix(odd_numbers, ncol = 10, nrow = 5)\n\n# Print the matrix to confirm\nprint(odd.mat)\n```\n````\n\n::: {.cell-output .cell-output-stdout}\n\n```\n     [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]\n[1,]    1   11   21   31   41   51   61   71   81    91\n[2,]    3   13   23   33   43   53   63   73   83    93\n[3,]    5   15   25   35   45   55   65   75   85    95\n[4,]    7   17   27   37   47   57   67   77   87    97\n[5,]    9   19   29   39   49   59   69   79   89    99\n```\n\n\n:::\n:::\n\n\n\n:::{.callout-tip collapse=\"true\"}\n## Explanation of the Code\n\nseq(from = 1, by = 2, length.out = 50) generates a sequence of 50 odd numbers starting from 1 (incrementing by 2).\nmatrix() takes the vector odd_numbers and reshapes it into a matrix with 10 columns and 5 rows.\nFinally, print(odd.mat) displays the matrix.\n:::\n\n# Q6. Strings: Sentences dataset\n\n>The goal of this question is to generate insights about the frequencies of the use of the definite article, \"The\" in the English composition.\n\n>(1) From \"sentences\" data that comes with stringr, which is included in Tidyverse package, confirm that you can correctly identify the first word from each sentence correctly by showing the first word from each sentence for all the sentences in the dataset. (2) Then, extract those first words and print out the first 20 words in the list of words extracted. Make sure you delete any white spaces, if any, before and after each extracted word. (3) Out of the words you extracted, how many times does the word, \"The,\" appear in the list? (4) What proportion of the extracted words does \"The\" account for? (5) Does the outcome surprise you? Explain why or why not. (6) Calculate the number of sentences that start with the word, \"The\" again, this time, using only one chain of codes with a series of the piping operator, starting with the \"sentences\" data set. Next, using a similar operation, calculate the proportion again.\n\n\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n# Load necessary libraries\nlibrary(tidyverse)\n\n# Load the sentences dataset from stringr package\ndata(\"sentences\")\n\n# Extract the first word of each sentence and remove white spaces\nfirst_words <- sentences %>%\n  str_extract(\"^\\\\S+\") %>%  # Extract the first non-space sequence (first word)\n  str_trim()  # Remove leading/trailing spaces\n\n# Print the first 20 words from the list of first words\nprint(first_words[1:20])\n\n# Count how many times \"The\" appears in the first words\nthe_count <- sum(tolower(first_words) == \"the\")\n\n# Print the result\nprint(the_count)\n\n# Calculate the proportion of \"The\" in the first words\nthe_proportion <- the_count / length(first_words)\n\n# Print the result\nprint(the_proportion)\n\n# Use piping to calculate the number of sentences starting with \"The\"\nthe_start_count <- sentences %>%\n  str_extract(\"^\\\\S+\") %>%\n  str_trim() %>%\n  tolower() %>%\n  .[ . == \"the\" ] %>%\n  length()\n\n# Print the result\nprint(the_start_count)\n\n# Calculate the proportion using piping\nthe_start_proportion <- the_start_count / length(sentences)\n\n# Print the result\nprint(the_start_proportion)\n```\n````\n\n::: {.cell-output .cell-output-stdout}\n\n```\n [1] \"The\"   \"Glue\"  \"It's\"  \"These\" \"Rice\"  \"The\"   \"The\"   \"The\"   \"Four\" \n[10] \"A\"     \"The\"   \"A\"     \"The\"   \"Kick\"  \"Help\"  \"A\"     \"Smoky\" \"The\"  \n[19] \"The\"   \"The\"  \n[1] 256\n[1] 0.3555556\n[1] 256\n[1] 0.3555556\n```\n\n\n:::\n:::\n\n\n\n\n\n# Q7. Strings: Baseball player stats in Lahman dataset\n\n>From the \"People\" dataset in the Lahman package, get all John's and Joe's from the first name column and display how many Joe's and John's there are in the dataset. Visualize the count of the two first names in a chart too. As usual, make the chart presentable.\n\n>*Hints*: You need to install Lahman package first and access \"People\" dataset that comes with the package. The dataset has information and statistics about baseball players such as Player names, DOB, and biographical info. This file is to be used to get details about players listed in the Batting, Pitching, and other files where players are identified only by playerID. For more information look up the help.\n\n\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n# Load necessary libraries\nlibrary(Lahman)\nlibrary(dplyr)\nlibrary(ggplot2)\n\n# Extract John's and Joe's from the People dataset\njohn_joe_count <- People %>%\n  filter(nameFirst %in% c(\"John\", \"Joe\")) %>%\n  count(nameFirst)\n\n# Print the count of Johns and Joes\nprint(john_joe_count)\n\n# Create a bar chart of the counts\nggplot(john_joe_count, aes(x = nameFirst, y = n, fill = nameFirst)) +\n  geom_bar(stat = \"identity\", width = 0.5) +\n  labs(title = \"Count of Baseball Players Named 'John' and 'Joe'\",\n       x = \"First Name\",\n       y = \"Count\",\n       fill = \"First Name\") +\n  theme_minimal() +\n  theme(text = element_text(size = 14)) +\n  scale_fill_manual(values = c(\"John\" = \"steelblue\", \"Joe\" = \"firebrick\"))\n```\n````\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  nameFirst   n\n1       Joe 413\n2      John 516\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](M07-2-Application-Assignment-for-R-Data-Types_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n:::\n\n\n\n\n\n# Q8. Factor-level ordering and Visualization\n\n>Install \"gapminder\" package if you don't have it already.\n\n>Q8.1: (1) From the package, use \"gapminder\" dataset. Examine the dataset to know it first. (1) First, print out the level of the \"continent\" factor from the gapminder data set. (2) From the most recent year in the dataset, calculate the total population by the continents and print out the outcome. (3) Print out the continent and total population again by arranging the appearance of the continent in descending order of the size of the population. (4) Compare both tables produced in (2) and (3) and describe how the order is different. Note that you haven't changed the factor level yet. Also, state how you could change the level of the factor by the descending order of the population size. (5) change the order of the level of the \"continent\" factor by the size of the continent's total population and save the change made to the continent by naming the data \"gapminder1\". Make sure you confirm the operation was successful.\n\n\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\nlibrary(gapminder)\n\nstr(gapminder)\nhead(gapminder)\n\nlevels(gapminder$continent)\n\nmax_year <- max(gapminder$year)\n\ncontinent_population <- gapminder |>\n  filter(year == max_year) |>\n  group_by(continent) |>\n  summarize(total_population = sum(pop))\n\nprint(continent_population)\n\ncontinent_population_sorted <- continent_population |>\n  arrange(desc(total_population))\n\nprint(continent_population_sorted)\n\n\ngapminder1 <- gapminder |>\n  mutate(continent = factor(continent, levels = continent_population_sorted$continent))\n\n# Verify the factor levels have been updated\nlevels(gapminder1$continent)\n```\n````\n\n::: {.cell-output .cell-output-stdout}\n\n```\ntibble [1,704 × 6] (S3: tbl_df/tbl/data.frame)\n $ country  : Factor w/ 142 levels \"Afghanistan\",..: 1 1 1 1 1 1 1 1 1 1 ...\n $ continent: Factor w/ 5 levels \"Africa\",\"Americas\",..: 3 3 3 3 3 3 3 3 3 3 ...\n $ year     : int [1:1704] 1952 1957 1962 1967 1972 1977 1982 1987 1992 1997 ...\n $ lifeExp  : num [1:1704] 28.8 30.3 32 34 36.1 ...\n $ pop      : int [1:1704] 8425333 9240934 10267083 11537966 13079460 14880372 12881816 13867957 16317921 22227415 ...\n $ gdpPercap: num [1:1704] 779 821 853 836 740 ...\n```\n\n\n:::\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"country\"],\"name\":[1],\"type\":[\"fct\"],\"align\":[\"left\"]},{\"label\":[\"continent\"],\"name\":[2],\"type\":[\"fct\"],\"align\":[\"left\"]},{\"label\":[\"year\"],\"name\":[3],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"lifeExp\"],\"name\":[4],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"pop\"],\"name\":[5],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"gdpPercap\"],\"name\":[6],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"Afghanistan\",\"2\":\"Asia\",\"3\":\"1952\",\"4\":\"28.801\",\"5\":\"8425333\",\"6\":\"779.4453\"},{\"1\":\"Afghanistan\",\"2\":\"Asia\",\"3\":\"1957\",\"4\":\"30.332\",\"5\":\"9240934\",\"6\":\"820.8530\"},{\"1\":\"Afghanistan\",\"2\":\"Asia\",\"3\":\"1962\",\"4\":\"31.997\",\"5\":\"10267083\",\"6\":\"853.1007\"},{\"1\":\"Afghanistan\",\"2\":\"Asia\",\"3\":\"1967\",\"4\":\"34.020\",\"5\":\"11537966\",\"6\":\"836.1971\"},{\"1\":\"Afghanistan\",\"2\":\"Asia\",\"3\":\"1972\",\"4\":\"36.088\",\"5\":\"13079460\",\"6\":\"739.9811\"},{\"1\":\"Afghanistan\",\"2\":\"Asia\",\"3\":\"1977\",\"4\":\"38.438\",\"5\":\"14880372\",\"6\":\"786.1134\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"Africa\"   \"Americas\" \"Asia\"     \"Europe\"   \"Oceania\" \n# A tibble: 5 × 2\n  continent total_population\n  <fct>                <dbl>\n1 Africa           929539692\n2 Americas         898871184\n3 Asia            3811953827\n4 Europe           586098529\n5 Oceania           24549947\n# A tibble: 5 × 2\n  continent total_population\n  <fct>                <dbl>\n1 Asia            3811953827\n2 Africa           929539692\n3 Americas         898871184\n4 Europe           586098529\n5 Oceania           24549947\n[1] \"Asia\"     \"Africa\"   \"Americas\" \"Europe\"   \"Oceania\" \n```\n\n\n:::\n:::\n\n\n\n\n\n>Q8.2: (1) Using the original gapminder data (not gapminder1), draw a chart that shows the total population by each continent in the year 2007, ordered by the size of the population in the chart. As usual, do this in one chain of codes and provide the necessary information and beautification to the chart to portray accurate communication to the viewers.\n\n\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n# Load necessary libraries\nlibrary(ggplot2)\nlibrary(dplyr)\n\n# Create the chart\ngapminder %>%\n  filter(year == 2007) %>%\n  group_by(continent) %>%\n  summarize(total_population = sum(pop)) %>%\n  ggplot(aes(x = reorder(continent, -total_population), y = total_population, fill = continent)) +\n  geom_bar(stat = \"identity\") +\n  labs(title = \"Total Population by Continent (2007)\", \n       x = \"Continent\", \n       y = \"Total Population\", \n       caption = \"Data Source: Gapminder\") +\n  theme_minimal() +\n  scale_fill_brewer(palette = \"Set2\") +  # Nice color theme\n  theme(legend.position = \"none\", \n        text = element_text(size = 12), \n        plot.title = element_text(hjust = 0.5, face = \"bold\"))\n```\n````\n\n::: {.cell-output-display}\n![](M07-2-Application-Assignment-for-R-Data-Types_files/figure-html/unnamed-chunk-12-1.png){width=672}\n:::\n:::\n\n\n\n\n\n>*Hints*: You don't need to confirm the success of the intended wrangling in a table format since you can confirm it in the chart. This way, you can avoid breaking the chain to confirm the level.\n\n::: {.callout-tip collapse=\"true\"}\n## Explanation of the Code\nQ8.1 Steps:\n\nChecked dataset structure (glimpse).\n\nPrinted factor levels of \"continent.\"\n\nFiltered data for the most recent year (2007) and calculated the total population per continent.\n\nArranged the results in descending order and compared them.\n\nReordered the factor levels based on population size and stored it in gapminder1.\n\nQ8.2 Visualization:\n\nThe bar chart displays total population by continent in 2007.\n\nThe fct_reorder() function ensures the x-axis is ordered by population size.\n\nUsed geom_col() for bars, coord_flip() for better readability, and theme_minimal() for a clean look.\n\n:::\n\n\n# Q9. Shortening Factor Levels: top or bottom 5 lists\n\nThe goal is to draw a chart that shows the top and bottom Asian countries by life expectancy in 2007. To do so, do the following:\n\n>Q9.1: let's first filter the unaltered gapminder dataset by the year 2007 and Asia continent and see how many countries there are in the filtered data. Do this using the piping operator all the time.\n\n\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\nlibrary(gapminder)\nlibrary(dplyr)\n\ngapminder %>%\n  filter(year == 2007, continent == \"Asia\") %>%\n  summarise(num_countries = n())\n\n#gapminder dataset contains the country-level data on life expectancy, GDP per capitia, and population in five-year interval. We are filtering for continent = Asia and year 2007. \n```\n````\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"num_countries\"],\"name\":[1],\"type\":[\"int\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"33\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\n\n\n\n>Q9.2: How many Asian countries do you see? Given\n\n33\n\n>Q9.3: Given the number of countries, it seems like a good idea to present the top 5 and bottom 5 countries, one at a time, and order the countries by life expectancy. Let's first focus on the top 5 list. Do appropriate wrangling and visualization for the top 5 list.\n\n*Hints*: Use functions from dplyr package to deal with top and bottom rankings. The function that will be most effective in finding the top or bottom five list would be slice_max() and slice_min(), respectively.\n\nTop 5 Asian Countries by Life Expectancy in 2007\n\n\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\nlibrary(gapminder)\nlibrary(dplyr)\nlibrary(ggplot2)\n\ntop_5_asia <- gapminder %>%\n  filter(continent == \"Asia\", year == 2007) %>%\n  slice_max(lifeExp, n = 5)\n\n#Slice_max(lifeExp, n = 5) extracts the top 5 contries by life expectancy \n\nggplot(top_5_asia, aes(x = reorder(country, lifeExp), y = lifeExp, fill = country)) +\n  geom_col(show.legend = FALSE) +\n  coord_flip() +\n  labs(title = \"Top 5 Asian Countries by Life Expectancy in 2007\",\n       x = \"Country\",\n       y = \"Life Expectancy\") +\n  theme_minimal()\n```\n````\n\n::: {.cell-output-display}\n![](M07-2-Application-Assignment-for-R-Data-Types_files/figure-html/unnamed-chunk-14-1.png){width=672}\n:::\n:::\n\n\n\n\n\nBottom 5 Asian Countries by Life Expectancy in 2007\n\n\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\nbottom_5_asia <- gapminder %>%\n  filter(continent == \"Asia\", year == 2007) %>%\n  slice_min(lifeExp, n = 5)\n\n#Slice_min(lifeExp, n = 5) extracts the bottom 5 contries by life expectancy\n\nggplot(bottom_5_asia, aes(x = reorder(country, lifeExp), y = lifeExp, fill = country)) +\n  geom_col(show.legend = FALSE) +\n  coord_flip() +\n  labs(title = \"Bottom 5 Asian Countries by Life Expectancy in 2007\",\n       x = \"Country\",\n       y = \"Life Expectancy\") +\n  theme_minimal()\n```\n````\n\n::: {.cell-output-display}\n![](M07-2-Application-Assignment-for-R-Data-Types_files/figure-html/unnamed-chunk-15-1.png){width=672}\n:::\n:::\n\n\n\n\n::: {.callout-tip collapse=\"true\"}\n## Explanation of the Code\nExplanation of the Code\nslice_max(lifeExp, n = 5) → Extracts the top 5 countries by life expectancy.\n\nslice_min(lifeExp, n = 5) → Extracts the bottom 5 countries by life expectancy.\n\nreorder(country, lifeExp) → Ensures countries are sorted in the bar chart.\n\ngeom_col() → Creates a bar chart.\n\ncoord_flip() → Flips the bars for better readability.\n\nMinimal theme (theme_minimal()) → Improves aesthetics.\n:::\n\n>Q9.4: Do similar wrangling and visualization to show the bottom 5 countries. (5) This time, let's put the two charts together and show them in one pallet by using the patchwork package \\<https://patchwork.data-imaginist.com/Links to an external site.\\>. The end result should look like this.\n\n\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\nlibrary(patchwork)\n\n\ntop_5_asia <- gapminder %>%\n  filter(continent == \"Asia\", year == 2007) %>%\n  slice_max(lifeExp, n = 5)\n\n\nbottom_5_asia <- gapminder %>%\n  filter(continent == \"Asia\", year == 2007) %>%\n  slice_min(lifeExp, n = 5)\n\n\nplot_top5 <- ggplot(top_5_asia, aes(x = reorder(country, lifeExp), y = lifeExp, fill = country)) +\n  geom_col(show.legend = FALSE) +\n  coord_flip() +\n  labs(title = \"Top 5 Asian Countries\",\n       x = \"Country\",\n       y = \"Life Expectancy\") +\n  theme_minimal()\n\n#Assign the top 5 plot a title \"plot_top5\"\n\nplot_bottom5 <- ggplot(bottom_5_asia, aes(x = reorder(country, lifeExp), y = lifeExp, fill = country)) +\n  geom_col(show.legend = FALSE) +\n  coord_flip() +\n  labs(title = \"Bottom 5 Asian Countries\",\n       x = \"Country\",\n       y = \"Life Expectancy\") +\n  theme_minimal()\n\n#Assign the bottom 5 plot a title \"plot_bottom5\"\n\nplot_top5 | plot_bottom5\n\n#patchwork could patch the plots either vertically \"/\" or horizontally \"|\"\n```\n````\n\n::: {.cell-output-display}\n![](M07-2-Application-Assignment-for-R-Data-Types_files/figure-html/unnamed-chunk-16-1.png){width=672}\n:::\n:::\n\n\n\n::: {.callout-tip collapse=\"true\"}\n## How This Works\nCreates two ggplots (plot_top5 and plot_bottom5).\n\nUses patchwork package (plot_top5 / plot_bottom5) to stack them vertically.\n\nBoth plots share the same styling, making it easier to compare.\n:::\n\n# Q10: Date-time data type (2 pts)\n\nThe goal is to deal with date-time data and visualize the data. The data is from the \"flights\" dataset that comes with the nycflights13 package. If you don't have it install the package and load up the data.\n\n>Q10.1. Look up the help to understand the data and also run appropriate functions to understand the data.\n\n\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#install.packages(\"nycflights13\")\nlibrary(nycflights13)\nlibrary(dplyr)\n```\n````\n:::\n\n\n\n\nCheck the dataset structure: this should give you the overview of the dataset like variable names and data types\n\n\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\nstr(flights)\n```\n````\n\n::: {.cell-output .cell-output-stdout}\n\n```\ntibble [336,776 × 19] (S3: tbl_df/tbl/data.frame)\n $ year          : int [1:336776] 2013 2013 2013 2013 2013 2013 2013 2013 2013 2013 ...\n $ month         : int [1:336776] 1 1 1 1 1 1 1 1 1 1 ...\n $ day           : int [1:336776] 1 1 1 1 1 1 1 1 1 1 ...\n $ dep_time      : int [1:336776] 517 533 542 544 554 554 555 557 557 558 ...\n $ sched_dep_time: int [1:336776] 515 529 540 545 600 558 600 600 600 600 ...\n $ dep_delay     : num [1:336776] 2 4 2 -1 -6 -4 -5 -3 -3 -2 ...\n $ arr_time      : int [1:336776] 830 850 923 1004 812 740 913 709 838 753 ...\n $ sched_arr_time: int [1:336776] 819 830 850 1022 837 728 854 723 846 745 ...\n $ arr_delay     : num [1:336776] 11 20 33 -18 -25 12 19 -14 -8 8 ...\n $ carrier       : chr [1:336776] \"UA\" \"UA\" \"AA\" \"B6\" ...\n $ flight        : int [1:336776] 1545 1714 1141 725 461 1696 507 5708 79 301 ...\n $ tailnum       : chr [1:336776] \"N14228\" \"N24211\" \"N619AA\" \"N804JB\" ...\n $ origin        : chr [1:336776] \"EWR\" \"LGA\" \"JFK\" \"JFK\" ...\n $ dest          : chr [1:336776] \"IAH\" \"IAH\" \"MIA\" \"BQN\" ...\n $ air_time      : num [1:336776] 227 227 160 183 116 150 158 53 140 138 ...\n $ distance      : num [1:336776] 1400 1416 1089 1576 762 ...\n $ hour          : num [1:336776] 5 5 5 5 6 5 6 6 6 6 ...\n $ minute        : num [1:336776] 15 29 40 45 0 58 0 0 0 0 ...\n $ time_hour     : POSIXct[1:336776], format: \"2013-01-01 05:00:00\" \"2013-01-01 05:00:00\" ...\n```\n\n\n:::\n:::\n\n\n\n\nVisulize the first few rows so that you are able to see the sample data\n\n\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\nhead(flights)\n```\n````\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"year\"],\"name\":[1],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"month\"],\"name\":[2],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"day\"],\"name\":[3],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"dep_time\"],\"name\":[4],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"sched_dep_time\"],\"name\":[5],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"dep_delay\"],\"name\":[6],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"arr_time\"],\"name\":[7],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"sched_arr_time\"],\"name\":[8],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"arr_delay\"],\"name\":[9],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"carrier\"],\"name\":[10],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"flight\"],\"name\":[11],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"tailnum\"],\"name\":[12],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"origin\"],\"name\":[13],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"dest\"],\"name\":[14],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"air_time\"],\"name\":[15],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"distance\"],\"name\":[16],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"hour\"],\"name\":[17],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"minute\"],\"name\":[18],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"time_hour\"],\"name\":[19],\"type\":[\"dttm\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"2013\",\"2\":\"1\",\"3\":\"1\",\"4\":\"517\",\"5\":\"515\",\"6\":\"2\",\"7\":\"830\",\"8\":\"819\",\"9\":\"11\",\"10\":\"UA\",\"11\":\"1545\",\"12\":\"N14228\",\"13\":\"EWR\",\"14\":\"IAH\",\"15\":\"227\",\"16\":\"1400\",\"17\":\"5\",\"18\":\"15\",\"19\":\"2013-01-01 05:00:00\"},{\"1\":\"2013\",\"2\":\"1\",\"3\":\"1\",\"4\":\"533\",\"5\":\"529\",\"6\":\"4\",\"7\":\"850\",\"8\":\"830\",\"9\":\"20\",\"10\":\"UA\",\"11\":\"1714\",\"12\":\"N24211\",\"13\":\"LGA\",\"14\":\"IAH\",\"15\":\"227\",\"16\":\"1416\",\"17\":\"5\",\"18\":\"29\",\"19\":\"2013-01-01 05:00:00\"},{\"1\":\"2013\",\"2\":\"1\",\"3\":\"1\",\"4\":\"542\",\"5\":\"540\",\"6\":\"2\",\"7\":\"923\",\"8\":\"850\",\"9\":\"33\",\"10\":\"AA\",\"11\":\"1141\",\"12\":\"N619AA\",\"13\":\"JFK\",\"14\":\"MIA\",\"15\":\"160\",\"16\":\"1089\",\"17\":\"5\",\"18\":\"40\",\"19\":\"2013-01-01 05:00:00\"},{\"1\":\"2013\",\"2\":\"1\",\"3\":\"1\",\"4\":\"544\",\"5\":\"545\",\"6\":\"-1\",\"7\":\"1004\",\"8\":\"1022\",\"9\":\"-18\",\"10\":\"B6\",\"11\":\"725\",\"12\":\"N804JB\",\"13\":\"JFK\",\"14\":\"BQN\",\"15\":\"183\",\"16\":\"1576\",\"17\":\"5\",\"18\":\"45\",\"19\":\"2013-01-01 05:00:00\"},{\"1\":\"2013\",\"2\":\"1\",\"3\":\"1\",\"4\":\"554\",\"5\":\"600\",\"6\":\"-6\",\"7\":\"812\",\"8\":\"837\",\"9\":\"-25\",\"10\":\"DL\",\"11\":\"461\",\"12\":\"N668DN\",\"13\":\"LGA\",\"14\":\"ATL\",\"15\":\"116\",\"16\":\"762\",\"17\":\"6\",\"18\":\"0\",\"19\":\"2013-01-01 06:00:00\"},{\"1\":\"2013\",\"2\":\"1\",\"3\":\"1\",\"4\":\"554\",\"5\":\"558\",\"6\":\"-4\",\"7\":\"740\",\"8\":\"728\",\"9\":\"12\",\"10\":\"UA\",\"11\":\"1696\",\"12\":\"N39463\",\"13\":\"EWR\",\"14\":\"ORD\",\"15\":\"150\",\"16\":\"719\",\"17\":\"5\",\"18\":\"58\",\"19\":\"2013-01-01 05:00:00\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\n\n\nWhen checking the column names you would be able to see all the variables in the dataset.\n\n\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\ncolnames(flights)\n```\n````\n\n::: {.cell-output .cell-output-stdout}\n\n```\n [1] \"year\"           \"month\"          \"day\"            \"dep_time\"      \n [5] \"sched_dep_time\" \"dep_delay\"      \"arr_time\"       \"sched_arr_time\"\n [9] \"arr_delay\"      \"carrier\"        \"flight\"         \"tailnum\"       \n[13] \"origin\"         \"dest\"           \"air_time\"       \"distance\"      \n[17] \"hour\"           \"minute\"         \"time_hour\"     \n```\n\n\n:::\n:::\n\n\n\n\nCheck the count of the rows and columns in the current dataset\n\n\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\ndim(flights)\n```\n````\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 336776     19\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\nsummary(flights)\n```\n````\n\n::: {.cell-output .cell-output-stdout}\n\n```\n      year          month             day           dep_time    sched_dep_time\n Min.   :2013   Min.   : 1.000   Min.   : 1.00   Min.   :   1   Min.   : 106  \n 1st Qu.:2013   1st Qu.: 4.000   1st Qu.: 8.00   1st Qu.: 907   1st Qu.: 906  \n Median :2013   Median : 7.000   Median :16.00   Median :1401   Median :1359  \n Mean   :2013   Mean   : 6.549   Mean   :15.71   Mean   :1349   Mean   :1344  \n 3rd Qu.:2013   3rd Qu.:10.000   3rd Qu.:23.00   3rd Qu.:1744   3rd Qu.:1729  \n Max.   :2013   Max.   :12.000   Max.   :31.00   Max.   :2400   Max.   :2359  \n                                                 NA's   :8255                 \n   dep_delay          arr_time    sched_arr_time   arr_delay       \n Min.   : -43.00   Min.   :   1   Min.   :   1   Min.   : -86.000  \n 1st Qu.:  -5.00   1st Qu.:1104   1st Qu.:1124   1st Qu.: -17.000  \n Median :  -2.00   Median :1535   Median :1556   Median :  -5.000  \n Mean   :  12.64   Mean   :1502   Mean   :1536   Mean   :   6.895  \n 3rd Qu.:  11.00   3rd Qu.:1940   3rd Qu.:1945   3rd Qu.:  14.000  \n Max.   :1301.00   Max.   :2400   Max.   :2359   Max.   :1272.000  \n NA's   :8255      NA's   :8713                  NA's   :9430      \n   carrier              flight       tailnum             origin         \n Length:336776      Min.   :   1   Length:336776      Length:336776     \n Class :character   1st Qu.: 553   Class :character   Class :character  \n Mode  :character   Median :1496   Mode  :character   Mode  :character  \n                    Mean   :1972                                        \n                    3rd Qu.:3465                                        \n                    Max.   :8500                                        \n                                                                        \n     dest              air_time        distance         hour      \n Length:336776      Min.   : 20.0   Min.   :  17   Min.   : 1.00  \n Class :character   1st Qu.: 82.0   1st Qu.: 502   1st Qu.: 9.00  \n Mode  :character   Median :129.0   Median : 872   Median :13.00  \n                    Mean   :150.7   Mean   :1040   Mean   :13.18  \n                    3rd Qu.:192.0   3rd Qu.:1389   3rd Qu.:17.00  \n                    Max.   :695.0   Max.   :4983   Max.   :23.00  \n                    NA's   :9430                                  \n     minute        time_hour                     \n Min.   : 0.00   Min.   :2013-01-01 05:00:00.00  \n 1st Qu.: 8.00   1st Qu.:2013-04-04 13:00:00.00  \n Median :29.00   Median :2013-07-03 10:00:00.00  \n Mean   :26.23   Mean   :2013-07-03 05:22:54.64  \n 3rd Qu.:44.00   3rd Qu.:2013-10-01 07:00:00.00  \n Max.   :59.00   Max.   :2013-12-31 23:00:00.00  \n                                                 \n```\n\n\n:::\n:::\n\n\n\n\n\n>Q10.2. Include only the records that do not have missing values in the following three variables: dep_time arr_time and air_time. Convert \"dep_time\" and \"arr_time\" to date-time data type, using \"year\", \"month\", and \"day\" as well as the hour and minutes information from \"dep_time\" and \"arr_time\". Then select only some useful columns we will need to draw a chart since there are too many columns to display. Those variables are \"origin\", \"dest\", \"air_time\", and any variables that start with 'dep' or 'arr.' Let's save this subset of the data as \"flights_lub.\"\n\n\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\nlibrary(lubridate)\n\nflights_lub <- flights %>%\n  filter(!is.na(dep_time), !is.na(arr_time), !is.na(air_time))\n\n#Filter Records with Non-Missing Values in dep_time, arr_time, and air_time\n\nflights_lub <- flights_lub %>%\n  mutate(\n    dep_time = make_datetime(year, month, day, dep_time %/% 100, dep_time %% 100),\n    arr_time = make_datetime(year, month, day, arr_time %/% 100, arr_time %% 100)\n  )\n\n#Convert dep_time and arr_time to Date-Time Data Type. We use the make_datetime() function from the lubridate package to combine year, month, day, and the extracted hours and minutes for both dep_time and arr_time.  \n\nflights_lub <- flights_lub %>%\n  select(origin, dest, air_time, starts_with(\"dep\"), starts_with(\"arr\"))\n\nhead(flights_lub)\n```\n````\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"origin\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"dest\"],\"name\":[2],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"air_time\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"dep_time\"],\"name\":[4],\"type\":[\"dttm\"],\"align\":[\"right\"]},{\"label\":[\"dep_delay\"],\"name\":[5],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"arr_time\"],\"name\":[6],\"type\":[\"dttm\"],\"align\":[\"right\"]},{\"label\":[\"arr_delay\"],\"name\":[7],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"EWR\",\"2\":\"IAH\",\"3\":\"227\",\"4\":\"2013-01-01 05:17:00\",\"5\":\"2\",\"6\":\"2013-01-01 08:30:00\",\"7\":\"11\"},{\"1\":\"LGA\",\"2\":\"IAH\",\"3\":\"227\",\"4\":\"2013-01-01 05:33:00\",\"5\":\"4\",\"6\":\"2013-01-01 08:50:00\",\"7\":\"20\"},{\"1\":\"JFK\",\"2\":\"MIA\",\"3\":\"160\",\"4\":\"2013-01-01 05:42:00\",\"5\":\"2\",\"6\":\"2013-01-01 09:23:00\",\"7\":\"33\"},{\"1\":\"JFK\",\"2\":\"BQN\",\"3\":\"183\",\"4\":\"2013-01-01 05:44:00\",\"5\":\"-1\",\"6\":\"2013-01-01 10:04:00\",\"7\":\"-18\"},{\"1\":\"LGA\",\"2\":\"ATL\",\"3\":\"116\",\"4\":\"2013-01-01 05:54:00\",\"5\":\"-6\",\"6\":\"2013-01-01 08:12:00\",\"7\":\"-25\"},{\"1\":\"EWR\",\"2\":\"ORD\",\"3\":\"150\",\"4\":\"2013-01-01 05:54:00\",\"5\":\"-4\",\"6\":\"2013-01-01 07:40:00\",\"7\":\"12\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\n\n::: {.callout-tip collapse=\"true\"}\n## Summary of Key Steps \nFilter rows with non-missing values in dep_time, arr_time, and air_time.\n\nConvert dep_time and arr_time from numeric values to proper date-time format.\n\nSelect relevant columns for visualization.\n\nThe final flights_lub dataset contains the necessary columns for plotting, ready for visualization or further analysis!\n:::\n\n\n>Q10.3. Using the \"dep_time\" variable, display the frequency distribution of the count of flights departing from New York City over the entire year in 2013, from Jan. 1 to Dec. 31.\n\n\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\nflights_lub %>%\n  mutate(dep_date = as.Date(dep_time)) %>%  \n  group_by(dep_date) %>%  \n  summarise(flight_count = n()) %>%  \n  ggplot(aes(x = dep_date, y = flight_count)) +\n  geom_line() + \n  labs(\n    title = \"Frequency Distribution of Flights Departing from NYC in 2013\",\n    x = \"Date\",\n    y = \"Number of Flights\"\n  ) +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1))  \n```\n````\n\n::: {.cell-output-display}\n![](M07-2-Application-Assignment-for-R-Data-Types_files/figure-html/unnamed-chunk-24-1.png){width=672}\n:::\n:::\n\n\n\n::: {.callout-tip collapse=\"true\"}\n## Explanation of Code\n\nmutate(dep_date = as.Date(dep_time)): Extract the date part from the dep_time variable to group the flights by date.\n\ngroup_by(dep_date): Group the dataset by the extracted dep_date.\n\nsummarise(flight_count = n()): Count the number of flights for each day.\n\nggplot(aes(x = dep_date, y = flight_count)): Create a line plot with the date on the x-axis and the count of flights on the y-axis.\n\ngeom_line(): Use a line plot to visualize the frequency distribution.\n\nlabs(): Add a title and labels to the x and y axes.\n\ntheme(axis.text.x = element_text(angle = 90, hjust = 1)): Rotate the x-axis labels to improve readability, especially for the date labels.\n\n:::\n\n>Q10.4. This time, let's zoom in on just one day, the Fourth of July holiday. Display the frequency distribution of the flights departing from New York City during the entire day.\n\n\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\nflights_lub %>%\n  filter(as.Date(dep_time) == \"2013-07-04\") %>% \n  mutate(dep_hour = format(dep_time, \"%H:%M\")) %>% \n  group_by(dep_hour) %>%  \n  summarise(flight_count = n()) %>%  \n  ggplot(aes(x = dep_hour, y = flight_count)) +\n  geom_bar(stat = \"identity\") +  \n  labs(\n    title = \"Frequency Distribution of Flights Departing from NYC on July 4, 2013\",\n    x = \"Time of Day\",\n    y = \"Number of Flights\"\n  ) +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1))  \n```\n````\n\n::: {.cell-output-display}\n![](M07-2-Application-Assignment-for-R-Data-Types_files/figure-html/unnamed-chunk-25-1.png){width=672}\n:::\n:::\n\n\n\n\n::: {.callout-tip collapse=\"true\"}\n## Explanation of Code\nfilter(as.Date(dep_time) == \"2013-07-04\"): Filter the dataset for flights that departed on July 4th, 2013.\n\nmutate(dep_hour = format(dep_time, \"%H:%M\")): Extract the hour and minute part from the dep_time variable to group the flights by time of day.\n\ngroup_by(dep_hour): Group the data by the extracted hour and minute.\n\nsummarise(flight_count = n()): Count the number of flights per time period (hour and minute).\n\nggplot(aes(x = dep_hour, y = flight_count)): Create a bar plot with the departure time on the x-axis and the count of flights on the y-axis.\n\ngeom_bar(stat = \"identity\"): Use a bar plot to display the frequency distribution.\n\nlabs(): Add a title and axis labels.\n\ntheme(axis.text.x = element_text(angle = 90, hjust = 1)): Rotate the x-axis labels for better readability, especially for the time of day.\n:::\n\n>Q10.5. Using the \"flights_lub\" dataset, create the \"travel_time\" variable by subtracting \"dep_time\" from \"arr_time\". Since arrival occurs later than departure, arr_time minus dep_time should be positive. Check this logic by sorting the data by the ascending order of \"travel_time\" Was the expectation met? No, because you will see negative minutes of travel_time. Pay attention to the type of data for travel_time. Why were there negative minutes?\n\n\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\nflights_lub <- flights_lub %>%\n  mutate(travel_time = as.numeric(difftime(arr_time, dep_time, units = \"mins\"))) \n\n\nflights_lub_sorted <- flights_lub %>%\n  arrange(travel_time)\n\n\nhead(flights_lub_sorted)\n```\n````\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"origin\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"dest\"],\"name\":[2],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"air_time\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"dep_time\"],\"name\":[4],\"type\":[\"dttm\"],\"align\":[\"right\"]},{\"label\":[\"dep_delay\"],\"name\":[5],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"arr_time\"],\"name\":[6],\"type\":[\"dttm\"],\"align\":[\"right\"]},{\"label\":[\"arr_delay\"],\"name\":[7],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"travel_time\"],\"name\":[8],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"EWR\",\"2\":\"BDL\",\"3\":\"21\",\"4\":\"2013-06-12 23:38:00\",\"5\":\"129\",\"6\":\"2013-06-12 00:17:00\",\"7\":\"102\",\"8\":\"-1401\"},{\"1\":\"EWR\",\"2\":\"ALB\",\"3\":\"26\",\"4\":\"2013-12-29 23:32:00\",\"5\":\"97\",\"6\":\"2013-12-29 00:14:00\",\"7\":\"74\",\"8\":\"-1398\"},{\"1\":\"EWR\",\"2\":\"ALB\",\"3\":\"29\",\"4\":\"2013-11-06 23:35:00\",\"5\":\"80\",\"6\":\"2013-11-06 00:18:00\",\"7\":\"61\",\"8\":\"-1397\"},{\"1\":\"EWR\",\"2\":\"BWI\",\"3\":\"33\",\"4\":\"2013-02-25 23:47:00\",\"5\":\"122\",\"6\":\"2013-02-25 00:30:00\",\"7\":\"111\",\"8\":\"-1397\"},{\"1\":\"EWR\",\"2\":\"BDL\",\"3\":\"24\",\"4\":\"2013-08-13 23:51:00\",\"5\":\"119\",\"6\":\"2013-08-13 00:35:00\",\"7\":\"97\",\"8\":\"-1396\"},{\"1\":\"EWR\",\"2\":\"MDW\",\"3\":\"92\",\"4\":\"2013-10-11 23:42:00\",\"5\":\"192\",\"6\":\"2013-10-11 00:27:00\",\"7\":\"142\",\"8\":\"-1395\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\n\n\n::: {.callout-tip collapse=\"true\"}\n## Explanation of Code\n\nmutate(travel_time = as.numeric(difftime(arr_time, dep_time, units = \"mins\"))): This calculates the time difference between the arr_time and dep_time in minutes. The difftime() function returns the difference as a difftime object, which we then convert to numeric minutes using as.numeric().\n\narrange(travel_time): This sorts the data by the travel_time in ascending order, so we can check if there are any negative values (which would indicate issues).\n:::\n\n>Q10.6. That was because those flights were overnight flights. The original dep_time had only hour and minutes information before day information was added and the time of arrival is smaller than the time of departure for the overnight flights. Thus, we need to fix \"arr_time\" by adding one more day when there was such an overnight flight. Do the appropriate adjustment prior to the travel_time variable creation in the chain of codes connected through a series of pipe operators. Also, convert the travel_time to a numeric data type. Show that there are no negative minutes anymore.\n\n\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\nflights_lub <- flights_lub %>%\n  mutate(\n    dep_time = with_tz(dep_time, tzone = \"America/New_York\"), \n    arr_time = with_tz(arr_time, tzone = \"America/New_York\")  \n  )\n\n\nflights_lub <- flights_lub %>%\n  mutate(travel_time = as.numeric(difftime(arr_time, dep_time, units = \"mins\")))\n\n\nnegative_travel_time <- flights_lub %>%\n  filter(travel_time < 0)\n\n\nhead(negative_travel_time)\n\n\nflights_lub_cleaned <- flights_lub %>%\n  filter(travel_time >= 0)\n\n\nhead(flights_lub_cleaned)\n```\n````\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"origin\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"dest\"],\"name\":[2],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"air_time\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"dep_time\"],\"name\":[4],\"type\":[\"dttm\"],\"align\":[\"right\"]},{\"label\":[\"dep_delay\"],\"name\":[5],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"arr_time\"],\"name\":[6],\"type\":[\"dttm\"],\"align\":[\"right\"]},{\"label\":[\"arr_delay\"],\"name\":[7],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"travel_time\"],\"name\":[8],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"EWR\",\"2\":\"BQN\",\"3\":\"192\",\"4\":\"2013-01-01 14:29:00\",\"5\":\"9\",\"6\":\"2012-12-31 19:03:00\",\"7\":\"-4\",\"8\":\"-1166\"},{\"1\":\"EWR\",\"2\":\"TPA\",\"3\":\"159\",\"4\":\"2013-01-01 15:58:00\",\"5\":\"-2\",\"6\":\"2012-12-31 19:08:00\",\"7\":\"9\",\"8\":\"-1250\"},{\"1\":\"EWR\",\"2\":\"SJU\",\"3\":\"199\",\"4\":\"2013-01-01 16:02:00\",\"5\":\"-6\",\"6\":\"2012-12-31 20:46:00\",\"7\":\"-12\",\"8\":\"-1156\"},{\"1\":\"EWR\",\"2\":\"SFO\",\"3\":\"354\",\"4\":\"2013-01-01 16:08:00\",\"5\":\"11\",\"6\":\"2012-12-31 19:25:00\",\"7\":\"-14\",\"8\":\"-1243\"},{\"1\":\"LGA\",\"2\":\"FLL\",\"3\":\"160\",\"4\":\"2013-01-01 16:20:00\",\"5\":\"-10\",\"6\":\"2012-12-31 19:16:00\",\"7\":\"-2\",\"8\":\"-1264\"},{\"1\":\"EWR\",\"2\":\"MCO\",\"3\":\"143\",\"4\":\"2013-01-01 16:21:00\",\"5\":\"41\",\"6\":\"2012-12-31 19:06:00\",\"7\":\"43\",\"8\":\"-1275\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div><div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"origin\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"dest\"],\"name\":[2],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"air_time\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"dep_time\"],\"name\":[4],\"type\":[\"dttm\"],\"align\":[\"right\"]},{\"label\":[\"dep_delay\"],\"name\":[5],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"arr_time\"],\"name\":[6],\"type\":[\"dttm\"],\"align\":[\"right\"]},{\"label\":[\"arr_delay\"],\"name\":[7],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"travel_time\"],\"name\":[8],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"EWR\",\"2\":\"IAH\",\"3\":\"227\",\"4\":\"2013-01-01 00:17:00\",\"5\":\"2\",\"6\":\"2013-01-01 03:30:00\",\"7\":\"11\",\"8\":\"193\"},{\"1\":\"LGA\",\"2\":\"IAH\",\"3\":\"227\",\"4\":\"2013-01-01 00:33:00\",\"5\":\"4\",\"6\":\"2013-01-01 03:50:00\",\"7\":\"20\",\"8\":\"197\"},{\"1\":\"JFK\",\"2\":\"MIA\",\"3\":\"160\",\"4\":\"2013-01-01 00:42:00\",\"5\":\"2\",\"6\":\"2013-01-01 04:23:00\",\"7\":\"33\",\"8\":\"221\"},{\"1\":\"JFK\",\"2\":\"BQN\",\"3\":\"183\",\"4\":\"2013-01-01 00:44:00\",\"5\":\"-1\",\"6\":\"2013-01-01 05:04:00\",\"7\":\"-18\",\"8\":\"260\"},{\"1\":\"LGA\",\"2\":\"ATL\",\"3\":\"116\",\"4\":\"2013-01-01 00:54:00\",\"5\":\"-6\",\"6\":\"2013-01-01 03:12:00\",\"7\":\"-25\",\"8\":\"138\"},{\"1\":\"EWR\",\"2\":\"ORD\",\"3\":\"150\",\"4\":\"2013-01-01 00:54:00\",\"5\":\"-4\",\"6\":\"2013-01-01 02:40:00\",\"7\":\"12\",\"8\":\"106\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\n\n\nIf the travel times are negative, it's a sign that the data might have issues, such as time zone mismatches or incorrect time entries. After identifying such cases, they can be corrected or removed from the dataset.\n\n>Q10.7. Once again, zoom in on the Forth of July. How many flights departed from New York City on that day? Create a plot that shows the relationship between the \"travel_time\" and \"air_time\" What do you infer from it? Why is there not a perfect association?\n\n\n\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\nflights_lub_cleaned <- flights_lub_cleaned %>%\n  mutate(\n    year = lubridate::year(dep_time),\n    month = lubridate::month(dep_time),\n    day = lubridate::day(dep_time)\n  )\n\n# Filter the data for July 4th, 2013\nflights_july4 <- flights_lub_cleaned %>%\n  filter(year == 2013, month == 7, day == 4)\n\n# How many flights departed on July 4th, 2013?\nnum_flights_july4 <- nrow(flights_july4)\nnum_flights_july4\n\n# Create a plot to show the relationship between travel_time and air_time\nggplot(flights_july4, aes(x = air_time, y = travel_time)) +\n  geom_point() +\n  labs(\n    title = \"Travel Time vs Air Time on July 4th, 2013\",\n    x = \"Air Time (minutes)\",\n    y = \"Travel Time (minutes)\"\n  ) +\n  theme_minimal()\n```\n````\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 717\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](M07-2-Application-Assignment-for-R-Data-Types_files/figure-html/unnamed-chunk-28-1.png){width=672}\n:::\n:::\n\n\n\n\nExpected Association: We might expect a positive correlation between air_time and travel_time because longer flights (in terms of air time) should generally take more time to reach their destination. However, travel_time includes not only the air time but also time spent taxiing, delays, and other factors that might increase the overall travel time.\n\nWhy No Perfect Association?:\n\nTaxing Time: A plane could have a very long taxiing time on the runway or waiting for clearance to depart or land, affecting travel_time but not air_time.\n\nDelays: Delays due to weather, air traffic control, or other factors might add to travel_time without affecting air_time.\n\nAircraft Routing: Sometimes, flights take longer routes or encounter air traffic, which would increase the travel_time but not necessarily the air_time.\n\nThis will show that while there is some correlation, it is not a perfect one due to other external factors impacting travel time.",
    "supporting": [
      "M07-2-Application-Assignment-for-R-Data-Types_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"../site_libs/pagedtable-1.1/css/pagedtable.css\" rel=\"stylesheet\" />\n<script src=\"../site_libs/pagedtable-1.1/js/pagedtable.js\"></script>\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}